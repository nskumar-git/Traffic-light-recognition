{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Autonomous Vehicles\n",
    "\n",
    "**Assignment: \tTraffic Light Recongition**\n",
    "\n",
    "**Student Name: Nithin Kumar**\n",
    "\n",
    "Here we attempt to classify traffic lights from the Bosch Small Traffic light dataset. We first import the training and test data (images and labels) and assemble into an array and dataframe, respectively. We also resize the images to speed up computation time. We then train our CNN with the training data and calculate the accuracy on the test data. We find we get around 60% accuracy on the test data and discuss this at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import patches\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from sklearn import metrics\n",
    "\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093\n",
      "8334\n"
     ]
    }
   ],
   "source": [
    "data_path = \"C:/Users/nithi/Desktop/traffic/\"\n",
    "\n",
    "with open(data_path + \"train.yaml\", \"r\") as test_file:\n",
    "    train_yaml = yaml.safe_load(test_file)\n",
    "with open(data_path + \"test.yaml\", \"r\") as test_file:\n",
    "    test_yaml = yaml.safe_load(test_file)\n",
    "print(len(train_yaml))\n",
    "print(len(test_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train data\n",
      "Processed 500 of 5093\n",
      "Processed 1000 of 5093\n",
      "Processed 1500 of 5093\n",
      "Processed 2000 of 5093\n",
      "Processed 2500 of 5093\n",
      "Processed 3000 of 5093\n",
      "Processed 3500 of 5093\n",
      "Processed 4000 of 5093\n",
      "Processed 4500 of 5093\n",
      "Processed 5000 of 5093\n",
      "Processed 5093 of 5093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Green', 'Red', 'Yellow', 'off'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=('path', 'x_min', 'y_min','x_max','y_max','target'))\n",
    "\n",
    "data_path = \"C:/Users/nithi/Desktop/traffic/\"\n",
    "\n",
    "# def image_scaling(img):\n",
    "#     res = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "#     return res\n",
    "\n",
    "print(\"creating train data\")\n",
    "x_train = []\n",
    "# y_train = []\n",
    "counter = 0\n",
    "for datapoint in train_yaml:\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"Processed {} of {}\".format(counter, len(train_yaml)))\n",
    "    pathname = datapoint[\"path\"]\n",
    "    image = cv2.imread(data_path+pathname)\n",
    "    resized = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    if datapoint[\"boxes\"]:\n",
    "        for i in range(0,len(datapoint[\"boxes\"])):\n",
    "            xmin = datapoint[\"boxes\"][i]['x_min']\n",
    "            xmax = datapoint[\"boxes\"][i]['x_max']\n",
    "            ymin = datapoint[\"boxes\"][i]['y_min']\n",
    "            ymax = datapoint[\"boxes\"][i]['y_max']\n",
    "            \n",
    "            if datapoint[\"boxes\"][i]:\n",
    "                if datapoint[\"boxes\"][i]['label'].startswith(\"Green\"):\n",
    "                    classname = \"Green\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"Red\"):\n",
    "                    classname = \"Red\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"Yellow\"):\n",
    "                    classname = \"Yellow\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"off\"):\n",
    "                    classname = \"off\"\n",
    "                else:\n",
    "                    print(datapoint[\"boxes\"][i]['label'])\n",
    "                    print(\"something wrong\")\n",
    "                dict1 = {'path': pathname, 'x_min': xmin, 'y_min': ymin, 'x_max': xmax, 'y_max': ymax, 'target': classname}\n",
    "                train_df = train_df.append(dict1, ignore_index = True)\n",
    "                x_train.append(resized)\n",
    "print(\"Processed {} of {}\".format(counter, len(train_yaml)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating test data\n",
      "Processed 500 of 8334\n",
      "Processed 1000 of 8334\n",
      "Processed 1500 of 8334\n",
      "Processed 2000 of 8334\n",
      "Processed 2500 of 8334\n",
      "Processed 3000 of 8334\n",
      "Processed 3500 of 8334\n",
      "Processed 4000 of 8334\n",
      "Processed 4500 of 8334\n",
      "Processed 5000 of 8334\n",
      "Processed 5500 of 8334\n",
      "Processed 6000 of 8334\n",
      "Processed 6500 of 8334\n",
      "Processed 7000 of 8334\n",
      "Processed 7500 of 8334\n",
      "Processed 8000 of 8334\n",
      "Processed 8334 of 8334\n"
     ]
    }
   ],
   "source": [
    "print(\"creating test data\")\n",
    "test_df = pd.DataFrame(columns=('path', 'x_min', 'y_min','x_max','y_max','target'))\n",
    "\n",
    "x_test = []\n",
    "counter = 0\n",
    "for datapoint in test_yaml:\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"Processed {} of {}\".format(counter, len(test_yaml)))\n",
    "    if datapoint[\"boxes\"]:\n",
    "        pathname = datapoint[\"path\"]\n",
    "        tmp = os.path.basename(pathname)\n",
    "        pathname = data_path+'rgb/test/'+tmp\n",
    "        image = cv2.imread(pathname)\n",
    "        resized = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        for i in range(0,len(datapoint[\"boxes\"])):\n",
    "            xmin = datapoint[\"boxes\"][i]['x_min']\n",
    "            xmax = datapoint[\"boxes\"][i]['x_max']\n",
    "            ymin = datapoint[\"boxes\"][i]['y_min']\n",
    "            ymax = datapoint[\"boxes\"][i]['y_max']\n",
    "            \n",
    "            if datapoint[\"boxes\"][i]:\n",
    "                if datapoint[\"boxes\"][i]['label'].startswith(\"Green\"):\n",
    "                    classname = \"Green\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"Red\"):\n",
    "                    classname = \"Red\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"Yellow\"):\n",
    "                    classname = \"Yellow\"\n",
    "                elif datapoint[\"boxes\"][i]['label'].startswith(\"off\"):\n",
    "                    classname = \"off\"\n",
    "                else:\n",
    "                    print(\"something wrong\")\n",
    "                    \n",
    "                dict1 = {'path': pathname, 'x_min': xmin, 'y_min': ymin, 'x_max': xmax, 'y_max': ymax, 'target': classname}\n",
    "                test_df = test_df.append(dict1, ignore_index = True)\n",
    "                x_test.append(resized)\n",
    "print(\"Processed {} of {}\".format(counter, len(test_yaml)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10756, 224, 224, 3)\n",
      "(13486, 224, 224, 3)\n",
      "(10756, 4)\n",
      "(13486, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train_np = np.array(x_train)\n",
    "x_test_np = np.array(x_test)\n",
    "x_train_np = x_train_np.astype('float32')\n",
    "x_test_np = x_test_np.astype('float32')\n",
    "x_train_np /= 255\n",
    "x_test_np /= 255\n",
    "print(x_train_np.shape)\n",
    "print(x_test_np.shape)\n",
    "\n",
    "y_train_np = OneHotEncoder().fit_transform(train_df[['target']]).toarray()\n",
    "y_test_np = OneHotEncoder().fit_transform(test_df[['target']]).toarray()\n",
    "\n",
    "print(y_train_np.shape)\n",
    "print(y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(224, 224,..., activation=\"relu\", strides=(2, 2), padding=\"same\")`\n",
      "  import sys\n",
      "C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 319,140\n",
      "Trainable params: 319,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_CHANNELS = 3\n",
    "IMAGE_WIDTH = 224 \n",
    "IMAGE_HEIGHT = 224\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = Sequential([\n",
    "  Convolution2D(16, 3, 3, border_mode='same', subsample=(2, 2), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(3, 3)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Convolution2D(32, 3, 3, border_mode='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(3, 3)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Convolution2D(64, 3, 3, border_mode='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dropout(0.3),\n",
    "  Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nithi\\anaconda3\\envs\\tfnew4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/8\n",
      " - 46s - loss: 1.0577 - accuracy: 0.4872\n",
      "Epoch 2/8\n",
      " - 40s - loss: 1.0366 - accuracy: 0.4981\n",
      "Epoch 3/8\n",
      " - 33s - loss: 1.0324 - accuracy: 0.5043\n",
      "Epoch 4/8\n",
      " - 32s - loss: 1.0238 - accuracy: 0.5147\n",
      "Epoch 5/8\n",
      " - 31s - loss: 1.0114 - accuracy: 0.5304\n",
      "Epoch 6/8\n",
      " - 31s - loss: 1.0046 - accuracy: 0.5344\n",
      "Epoch 7/8\n",
      " - 31s - loss: 0.9956 - accuracy: 0.5396\n",
      "Epoch 8/8\n",
      " - 31s - loss: 0.9905 - accuracy: 0.5461\n",
      "Test loss: 0.820100229951159\n",
      "Test accuracy: 0.5998072028160095\n",
      "Elapsed time: 0:05:10.66\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 8\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(x_train_np, y_train_np,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2)\n",
    "score = model.evaluate(x_test_np, y_test_np, verbose=0)\n",
    "\n",
    "print('Test loss: {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.599807207474418\n"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y_test_np,axis=1)\n",
    "model_pred = model.predict(x_test_np)\n",
    "pred = np.argmax(model_pred,axis=1)\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "r = pd.DataFrame( { 'y': y_test, \"pred\": pred})\n",
    "r.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get around 60% accuracy on the test data. One issue I found that were not many training images with yellow or green lights. Most of them were red or off (driving). Our predictions on the test data mostly predicted 0 or 1 as shown in the output.csv file (corresponding to off or red).\n",
    "The model itself is fairly simple - there are about 320,000 parameters with ReLU activation but we are not employing some of the state-of-the-art techniques such as Faster R-CNN. \n",
    "Furthermore, I had to downsample the images (to 224x224x3) or else the computation time was too long. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
